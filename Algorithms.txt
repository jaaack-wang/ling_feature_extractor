The following are brief descriptions about the algorithms used in this study to extract linguistic features, whose frequencies are all normalized at the rate of 100 words, except feature 1, 4 and 5. The algorithms are greatly inspired by Biber (1988) and Nini (2014). 
For practical purposes, pure and lengthy lexical features that are not tested against Nini’s MAT program are not covered in detail here. Please refer to the citation besides or check out the source codes at https://github.com/jaaack-wang/ling_feature_extractor instead.
	Global Settings
All the POS tags used in this study are from Penn Treebank tag set, except that NOT (see below) is re-tagged as NEG when the feature extraction starts. To know more about the tag sets, please refer to https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html.
Please note that, the following transcriptions have special meanings: bold text refers to a defined variable; underline text stands for a POS tag plus the tagged words; italic text indicates a word; parentheses (), when having a bold or underline text inside, mean that any feature inside is optional; plus sign + implies a combination rule; strikethrough is only applied for those false positives; and brackets [] are used to highlight a targeted feature/pattern in the cited examples based on the algoirthms. All these examples are randomly selected from the corpus.
Token: any space-separated string.
Word: TOKEN that has been tokenized by Stanford POS tagger except symbols, processive endings. Additionally, hyphen-connected-token is always treated as a word.
NOT: not or its contracted form n’t, all re-tagged as “NEG” when extracting features.  
BE: am, is, are, was, were, be, being, been, ‘m and ‘re. Nini (2014) also includes ‘s, which, however, sometimes leads to confusing is with has. See feature 8 for explanation.
LINKING_V: linking verb, including BE; become, seem, grow, look, prove, remain, smell, sound, taste, turn, get, appear, feel and their inflected forms. See feature 78 for example. 
HAVE: have, has, had, having, ‘ve, ‘d and hath (‘s not included). It was found that, due to a small bug, the MAT actually fails to recognize ‘ve as HAVE, which affects the tagging of all features related to HAVE and AUX (see below), such as feature 11 and 14. Besides, Nini (2014) also omits ‘d here, which is problematic. Although ‘d is poorly tagged in the 2013 Stanford POS tagger, often confused with the contracted would, except when it is used as part of AUX, it only appears in the feature 11 and is already disambiguated by the context.
DO: do, does and did. Unlike Biber (1988) and Nini (2014), doing and done are not included to improve the extraction precision because DO is mainly used as AUX (see below) here and they are certainly not AUX. Including them only causes some systematic and unexpected problems whenever DO is used as AUX indiscriminately. For example, for feature 14, the MAT mistakenly tags structure like “what I ‘ve [done here is] to try…” (ahlct039) as spilt auxiliary. For feature 96, similar structure like “what they ‘re [doing is] acting…” (lclct044) is mistakenly tagged as emphatics by the MAT. These problems appear to be not uncommon. 
MODAL: any WORD POS tagged as MD.
AUX: auxiliary, including BE, HAVE, DO, MODAL and ‘s when used as a verb. 
ADV: adverb, any WORD POS tagged as RB.
ADJ: adjective, any WORD POS tagged as JJ, JJR and JJS.
VERB: any WORD POS tagged as VB, VBD, VBG, VBN, VBP and VBZ.
NOUN: any WORD POS tagged as NN, NNS, NNP and NNPS.
DEM: demonstrative, including this, those, these, and DT that. Will be disambiguated in contexts. See SUBPRP, OBJPRP and feature 57 for disambiguation. 
ART: article, including a, an and the.
NMOD: noun modifier, including any WORD POS tagged as PDT (predeterminer), DT (determiner) CD (cardinal number) and PRP$ (possessive pronoun); ADJ and ART.
QUANPRP: quantitative pronoun, including everybody, somebody, anybody, everyone, someone, anyone, everything, something, anything.
SUBPRP: subject pronoun, including I, we, he, she, they, you, it, DEM and QUANPRP. Biber’s (1988) algorithm is improved by adding you, it, and DEM into SUBPRP, which will be disambiguated by the contexts. The same goes for OBJPRP.
OBJPRP: object pronoun, including me, us, him, her, them, you, it, and DEM.
SUBJ: subject, including (ART) + (NOMD) + NOUN and SUBPRP.
OBJ: object, including (ART) + (NOMD) + NOUN and OBJPRP.
CC: coordinator, including and & or, which improves Biber (1988) and Nini’s (2014) algorithm by also allowing or as a coordinator. See feature 15, 16 for examples. Also note that CC as a tag means coordinating conjunction and can include more than just and & or.
WHP: WH relative pronoun, including who, whom, which and whose + (NMOD) + NOUN. The algorithm in Biber (1988) and Nini (2014) is improved as whose is specified to have a NOUN following with a possible NMOD, without which whose alone does not make a relative pronoun and no valid cases can be thus extracted. See feature 20, 21, 22 for examples.
WHO: WH question words, including what, where, when, how, whether, why, whoever, whomever, whichever, wherever, whenever, whatever and however.
PREP: preposition, including against, amid, amidst, among, amongst, at, besides, between, by, despite, during, except, for, from, in, into, minus, notwithstanding, of, off, on, onto, opposite, out, per, plus, pro, re, than, through, throughout, thru, to, towards, upon, versus, via, with, within and without. They must be at the same time POS tagged as IN.
	Feature Patterns
(A)	 Structural Features
1.	Words per utterance (WPU). The number of WORDs divided by the number of UTTERANCEs (see below).
2.	Utterance (UTT). Any <u> tag in BASE or <U1> and <U2> tag in MICASE. 
3.	6-letter words and above (SLW). WORD longer than 5 characters. 
4.	Mean word length (MWL). The number of characters, excluding punctuations, divided by the number of WORDs. Nini’s (2014) algorithm is improved as it also counts hyphens as part of the characters in hyphen-connected WORDs, which consistently increases the value of MWL in a slight but significant way. 
5.	 Type-token ratio (TTR). The number of unique lemmatized WORDs divided by the number of WORDs. This improves the algorithms provided by Biber (1988) and Nini (2014) who do not lemmatize the words. 

(B)	Conversational Features
6.	Overlap (OLP). Any <u trans=“overlap”> tag in BASE and any <OVERLAP> tag in MICASE.
7.	Contraction (CONT). Contractions are only limited to NOT and AUX, based on Biber (1988), so possessive ‘s or ’ (preceded by s),  and any other WORDs with an apostrophe in it, such as c’mon, ‘cause, or sometimes foreign words, e.g., d’esprit, are excluded. Other would-be contractions are not included simply because they are not always equally transcribed for both BASE and MICASE, or even across transcribers. Nini’s (2014) algorithm is improved as it also counts other non-possessive WORDs that contain apostrophe in it when mistakenly POS tagged as a verb.

(C)	Sentential Features
Passive voice
8.	Agentless passive (AGPA). When used in a statement: BE + (NOT or ADV) + (NOT or ADV) + VBN (i.e., past particle) + anything but by; when used in a question: BE + (NOT) + SUBJ + (ADV) + VBN + anything but by. Nini’s (2014) algorithm is improved as the VBD (past tense) is not included here, which was found to be very poor at accurately tagging AGPA, such as: “problem [was they got]…” (lslct049). Besides, as ‘s is included in Nini’s (2014) algorithm, the MAT many times mistakenly count perfect aspect as AGPA. Please see feature 11.
9.	passive (BYPA). Same patterns with AGPA but ends with by. Additionally, ‘s used as VERB is included here (BE or ‘s) as its usage is disambiguated in this context.
Tense
10.	Past tense (PAST). Any WORD POS tagged as VBD. 
11.	Perfect aspect (PEAS). When used in a statement: HAVE (+ NOT or ADV) (+ NOT or ADV) + VBN or VBD; when used in a question: HAVE (+ NOT) + SUBJ (+ ADV) + VBN or VBD. VBD is added following Nini (2014) because the context disambiguates it and it finds cases where VBN is mis-tagged as VBD. As mentioned above, the MAT fails to recognize ‘ve and omit ‘d. See HAVE.
12.	Non-past tense (NONP). Any WORD POS tagged as VB, VBP or VBZ.
13.	Progressive tense (VING). When used in a statement: BE or ‘s + (NOT or ADV) + (NOT or ADV) + VBG; when used in a question: BE or ‘s + (NOT) + SUBJ + (ADV) + VBG. VERB ‘s is added because it is disambiguated by the context. 
Split structures
14.	Split auxiliaries (SPAU). AUX + (NOT) + ADV + (ADV) + VERB. Example: “I [‘ve always thought]…” (ahlct001). Nini’s (2014) algorithm is corrected as it does not allow a possible NOT after the AUX, which Biber (1988) does. Also, both Biber (1988) and Nini (2014) include doing and done in AUX, which causes problems too as they are not really AUX. See DO.
Coordination
15.	Phrasal coordination (PHCO). X + CC + X, where X can be NOUN, ADJ, ADV or VERB. Note that CC here also includes or which Biber (1988) and Nini (2014) do not and the inclusion apparently increases the recall rate. See CC. 
16.	Independent clause coordination (CLCO). A coordinator followed by a clause, where a possible ADV or IN is allowed to intervene in between: CC (+ ADV or IN) + SUBJ or there or WHO or WHP (+ ADV) (+ AUX + (NOT) or ADV) + AUX or VERB. Biber’s (1988) algorithm, which Nini (2014) follows, is generalized and in a way rewritten here as it is specifically assumed that the corpus is unpunctuated and more context is needed to make sure that what follows the coordinator is a clause, containing a verb phrase. Example: “[or sometimes it ‘s] called antique…” (ahlct040); “and [it ‘ll be] the first time…” (lslct043). Comparatively, as my algorithm strictly requires a clear trace of clause that follows after CC, it is more precise than Biber (1988) and Nini (2014). At the meantime, as CC is allowed to have extra or in it and the algorithm is punctuation independent, it can extract more cases. 
WH structure
17.	WH question (WHQ). WHO + AUX + (NOT or ADV) + (NOT or ADV) + SUBJ. In Biber (1988) and Nini (2014), WHQ is highly dependent on punctuations followed by WHO + AUX. However, this pattern does not work at all when a corpus is unpunctuated, so the MAT cannot find any cases of WHO for this study. Therefore, algorithm for WHO is entirely rewritten here. Example: “[how can the director] remain faithful to…” (ahlct017). 
18.	WH clause (WHC). When WH question words are not followed by an AUX and therefore do not form a question: WHO + anything but AUX; When what is followed by a VERB with a possible combination of AUX, NOT and ADV but does not form a question (not followed by a SUBJ): what + (AUX + (NOT) or ADV) + (ADV) + VERB + (NOT) + anything but SUBJ. The reason why a NOT is allowed after the VERB is because VERB can also be BE, DO, or HAVE. Examples: “[where psychologists] start to depart is [when you] start talking about evolutionary influences…” (sslct054); “look at what [what ‘s normal]” (lslct027). These two rules totally rewrite Biber’s (1988) algorithm: public/private/suasive VERB + WHO + anything but AUX. Nini (2014) also follows it. Although this pattern does identify WHC, the recall is extremely low compared to the widespread existence of WHC in classroom discourses. This is because the algorithm only recognizes WHC that follows a limited list of VERBs and functions as an object, which is apparently very single-sided and untrue. Therefore, it is not followed in this study. 
Nominal postmodifying clauses
19.	That relative (THRA). Any that tagged as WDT, which is a relative pronoun; when that is used as a subject in the following clause, namely, followed by an AUX or VERB with a possible NOT for AUX or an possible ADV for both: NOUN + that + (AUX + (NOT) or ADV) + AUX or VERB; when that is used as an object in the following clause, namely, followed by an SUBJ: NOUN + that + SUBJ. Examples: “marginal [revenue that implies] a price of…” (pslct012); “ecological [studies that we do n’t have]…” (lslct049).  
20.	WH relative on subject position (WHRS). Anything but ask or tell + WORD + NOUN or PRP + WHP + (AUX + (NOT) or ADV) + AUX or VERB. The reason ask and tell are forbidden two words before the NOUN is to avoid indirect question. Follows Biber’s (1988) algorithm. Example: “the [idealists who said] this was…” (sslct018). Besides, PRP is additionally added to increase the recall. 
21.	WH relative on object position (WHRO). Anything but ask or tell + WORD + NOUN or PRP + WHP + SUBJ. In Biber’s (1988) algorithm, the last element is set as anything but ADV, AUX or VERB, in other words, to exclude WHRS. However, when the codes are written that way, which can be proven by the MAT, there are many negative positives that are actually WHRS, if the last element is not a SUBJ. Examples: “another school of [thought which in] fact was probably sanctioned…” (ahlct008); “this [valley today] is of the most…” (ahlct045). With that said, I do not add this rule to the previous WHRS, because this pattern is still unpredictable in the messy spoken text and may lower down the overall precision. Besides, PRP is additionally added to increase the recall.  
22.	WH relative with fronted preposition (WHRFP). PREP + WHP. Follows Biber’s (1988) algorithm. Example: “the year [in which] empire is declared for” (ahlct004).
23.	Past participial postnominal clause (PPPCL). NOUN or QUANPRP + VBN + PREP or BE or ADV. Follows Biber’s (1988) algorithm. Examples: “describe visual arts [arts made] made between the nineteen-sixties…” (ahlct050); “those two [individuals taken] at random…” (lslct011). 
“To” clause preceded by
24.	Speech act verb (TSAV). TSAV + to. See Biber (2006: 34) for the TSAV word list, such as: ask, advise, beg, beseech, call and claim etc. 
25.	Cognition verb (TCOV). TCOV + to. See Biber (2006: 34) for the TCOV word list, such as: assume, believe, consider, estimate, expect, find and forget etc.
26.	Desire/intent/decision verb (TDIDV). TDIDV + to. See Biber (2006: 34) for the TDIDV word list, such as: aim, agree, bear, care, choose, consent and dare etc.
27.	Modality/cause/effort verb (TMCEV). TMCEV + to. See Biber (2006: 34) for the TMCEV word list, such as: afford, allow, appoint, arrange and assist etc.
28.	Probability/simple fact verb (TPSFV). TPSFV + to. See Biber (2006: 34) for the TPSFV word list, i.e., appear, happen, seem, tend and their inflected forms.
29.	Certainty adjective (TCAJ). TCAJ + to. See Biber (2006: 35) for the TCAJ word list, i.e., apt, certain, due, guaranteed, liable, likely, prone, unlikely and sure.
30.	Ability/willingness adjective (TAWAJ). TAWAJ + to. See Biber (2006: 35) for the TAWAJ word list, such as able, anxious, bound, careful and competent etc.
31.	Personal affect adjective (TPAAJ). TPAAJ + to. See Biber (2006: 35) for the TPAAJ word list, such as: afraid, amazed, angry, annoyed and ashamed etc.
32.	Ease/difficulty adjective (TEDAJ). TEDAJ + to. See Biber (2006: 35) for the TEDAJ word list, such as: difficult, easy, hard, impossible and pleasant etc.
33.	Evaluative adjective (TEVAJ). TEVAJ + to. See Biber (2006: 35) for the TEVAJ word list, such as: awkward, appropriate, bad, best, better, brave and careless etc.
34.	Control Noun (TCNO). TCNO + to. See Biber (2006: 33) for the TCNO word list, such as agreement, authority, commitment, confidence and decision etc. 
“That” clause preceded by
35.	Nonfactive noun (THNFN). THNFN + that. See Biber (2006: 33) for the THNFN word list, such as: comment, news, proposal, proposition and remark etc.
36.	Attitudinal noun (THATN). THATN + that. See Biber (2006: 33) for the THATN word list, i.e., ground, hope, reason, view, thought and their plural forms.
37.	Factive noun (THFAN). THFAN + that. See Biber (2006: 33) for the THFAN word list, such as: assertion, conclusion, conviction, discover, doubt and fact etc.
38.	Likelihood noun (THLKN). THLKN + that. See Biber (2006: 33) for the THLKN word list, such as: assumption, belief, claim, contention, expectation and feeling etc.
39.	Nonfactive verb (THNFV). THNFV + that. See Biber (2006: 33) for the THNFV word list, such as: add, announce, advise, answer, argue, allege, ask and assure etc.
40.	Attitudinal verb (THATV). THATV + that. See Biber (2006: 33) for the THATV word list, such as: accept, admit, agree, anticipate, boast, complain and concede etc.
41.	Factive verb (THFV). THFV + that. See Biber (2006: 34) for the THFV word list, such as: acknowledge, affirm, ascertain, calculate, certify, check and conclude etc.
42.	Likelihood verb (THLKV). THLKV + that. See Biber (2006: 34) for the THLKV word list, such as: appear, assume, believe, bet, conceive, consider and deduce etc.
43.	Likelihood adjective (THLKAJ). THLKAJ + that. See Biber (2006: 35) for the THLKAJ word list, i.e., doubtful, likely, possible, probable and unlikely. 
44.	Attitudinal adjective (THATAJ). THATAJ + that. See Biber (2006: 34-35) for the THATAJ word list, such as: acceptable, adamant, advisable, afraid and amazed etc.

(D)	Lexical Features 
Part of speech
45.	Noun (NOUN). See Global Setting above.
46.	Verb (VERB). See Global Setting above.
47.	Noun modifier (NMOD). See Global Setting above.
48.	Article (ART). See Global Setting above.
49.	Modal (MD). See Global Setting above.
50.	Negator (NEG). See Global Setting above.
51.	Preposition (PREP). See Global Setting above.
Pronoun
52.	First person pronoun (FPP). I, me, us, ‘s as in let’s, my, we, our, myself and ourselves. Nini’s (2014) algorithm is improved as the contracted ‘s is not included.
53.	“I” reference (IRF). I, me, my, myself.
54.	Second person pronoun (SPP). You, your, yourself, yourselves, thy, thee, thyself and thou. Follows Nini’s (2014) algorithm.
55.	Third person pronoun (TPP). He, she, they, her, him, them, his, their, himself, herself and themselves.
56.	Pronoun it (PIT). It, its, itself.
57.	Demonstrative pronoun (DEMP). DEM + AUX or VERB or WHO or WHP or CC or IN. Biber (1988) and Nini’s (2014) algorithm is expanded here by allowing DEM followed by WHO, CC and IN also to be recognized as a DEMP because clearly in these situations DEM do not modify those following components and therefore should be considered as DEMP. Besides, Biber (1988) and Nini (2014) sees every that ‘s and that is as DEMP regardless of the type of that. This study requires that that must be POS tagged as DT, namely, determiner, to avoid confusing relative noun that and IN that as DEMP. See DEM and feature 19. Examples: “so [this is] the first of…” (sslct036); “like [that at] the beginning of…” (sslct040).
58.	Indefinite pronoun (INDP). Anybody, anyone, anything, everybody, everyone, everything, nobody, none, nothing, nowhere, somebody, someone and something. In Nini’s (2014) MAT, this feature is later largely overwritten by the QUANPRP, so only nobody, none, nothing and nowhere are in reality identified by it. 
Noun sub-categories
59.	Nominalization (NOMZ). NOUN that ends with -tion, -ment, -ness, -ity and their corresponding plural forms.
60.	Animate noun (ANMN). Such as: family, guy, individual, kid, man, and manager etc. See Biber (2006: 28).
61.	Cognitive noun (COGN). Such as: analysis, decision, experience, assessment, and calculation etc. See Biber (2006: 28).
62.	Concrete noun (CONN). Such as: tank, stick, target, strata, telephone, sugar and ticket etc. See Biber (2006: 28).
63.	Technical noun (TCHN). Such as: cell, unit, gene, wave, ion, bacteria and election etc. See Biber (2006: 29).
64.	Quantity noun (QUAN). Such as: cycle, rate, date, second, frequency, section and semester etc. See Biber (2006: 29).
65.	Place noun (PLAN). Such as: apartment, interior, bathroom, moon, bay, museum and bench etc. See Biber (2006: 29).
66.	Group/institution noun (GIN). Such as: airline, institute, colony, bank, flight and church etc. See Biber (2006: 29). 
67.	Abstract/process noun (APN). Such as: action, activity, application, argument and development etc. See Biber (2006: 29-30).
Verb sub-categories
68.	“Be” as main verb (BEMV). BE or ‘s as VERB + (NOT or ADV) + (NOT or ADV) + NMOD or IN; BE or ‘s as + ADV (+ ADV) + PRP. This algorithm is different from Biber (1988) and Nini (2014) by also including subordinating conjunctions, not just PREP, because BE is certainly a main verb when followed by a subordinating clause. Examples: “assignment [is on] Monday…” (sslct053); “that [‘s because] for today…” (sslct049). Nini (2014) excludes all instances of there be, which is felt unnecessary. Although there be is certainly a special type of structure, be as in there be is no doubt a main verb. The last piece of the algorithm follows Nini (2014), but an ADV is made compulsory to avoid BE used in questions.
69.	Pro-verb do (PROD). Biber (1988) speculates two conditions for PROD: DO + anything but (ADV +) VERB, namely, not used as an emphatic; anything but punctuations or WHP + DO, to avoid a question. Nini (2014) also adds WHO as an alternative to WHP, which Biber might have missed by chance. However, the DO is problematic in their algorithms as they include doing and done in DO, which are certainly PROD already. See DO and feature 14. Conversely, as such, that causes many false negatives that will never be identified, like: “what they [‘re doing are] good…” (ahlct014); “what Sulla had [done was] repealed by…” (ahlct042). Besides, their algorithm also ignores DO used in relative clauses as PROD, such as: “artificial network [which does something] really quite interesting…” (pslct035); “a student [who actually did] his M-A…” (sslect039). My algorithm: doing or done; not in a WH question: anything but WHO (+ ADV) + DO; not used in a question or as an emphatic: DO + anything but NOT or (ADV +) VERB or SUBPRP; used in relative clauses but not in a question or as emphatic: NOUN or PRP + WHP (+ AUX (+ NOT) or ADV) + DO + anything but NOT or (ADV +) VERB or SUBPRP.   
70.	Activity verb (ACTV). Such as: buy, make, get and take etc. See Biber (2006: 30).
71.	Communication verb (COMV). Such as: say, tell, call, ask, write, and talk etc. See Biber (2006: 31).
72.	Mental verb (MENV). Such as: see, know, think, find, want, mean, and need etc. See Biber (2006: 30-31).
73.	Causative verb (CAUV). Such as: help, let, allow, affect, cause, enable and ensure etc. See Biber (2006: 31).
74.	Occurrence verb (OCCV). Such as: become, happen, change, die, grow and develop etc. See Biber (2006: 31).
75.	Existence verb (EXV). Such as: seem, look, sound, stay, live, appear, and include. See Biber (2006: 31).
76.	Aspectual verb (ASPV). Such as: start, keep, stop, begin, complete and end etc. See Biber (2006: 31).
Adjective sub-categories
77.	Attributive adjective (ATTAJ). When followed by a NOUN or the pronoun one or ones with a possible combination of CC and ADJ: ADJ (+ CC)  (+ ADJ) + NOUN or one or ones; when preceded by the or QUANPRP becoming an noun phrase: the or QUANPRP + ADJ. Examples: “a [comprehensive list]” (lslct039); “[good and [bad attitudes]]” (lslct021); “a [moral one]” (ahlct043). However, in Biber (1988) and Nini (2014),  ATTAJ is basically equal to the opposite of PREAJ (see below), so ADJ not identified as PREAJ is by default considered as ATTAJ. This is rather problematic as (1) their definition of PREAJ is rather problematic, as shown below; (2) the tagging of ADJ is not perfect so binarism does not work well; (3) ADJ might not be simply binary. False positives by the MAT: “[F-of-X-star] equals zero” (pslct038); “that will bring us [close] to this root…” (pslct038); “yes [good] [okay] today we are…” (sslct045); “that sounds a [little] [weird]…” (sslctp45). ADJ is very frequently used, the less restrictions on the ATTAJ, the more erroneous it will be. This study takes a conservative position and only extracts ATTAJ based on the above rules.  
78.	Predictive adjective (PREAJ). In Biber (1988) and Nini (2014), PREAJ must be preceded by a BE and followed by anything but ADJ or NOUN. Nini (2014) allows an ADJ preceded by PREAJ + and to be tagged as PREAJ, but unlike Biber (1988), it does not allow PREAJ followed by an ADV. Only allowing BE preceding PREAJ is rather problematic and causes many false negatives as at least all PREAJs can be preceded by any VERB listed in LINKING_V, examples: “[seems very solid]” (sslct050); “[that becomes very explicit]” (sslct050); “to [grow faster] you ‘re…” (lslct017); “you [get older]” (lslct017). Similarly, PREAJ can also exist in questions, which both Biber and Nini ignore. Examples: “how effective [are they likely to] be” (lslct014); “[is everybody happy about] that” (lslct018); “[is it smooth] [is it rough]” (lslct023). Plus, neglecting ADV following BE + ADJ as PREAJ is largely wrong. I manually checked all the targeted patterns in ah files, almost all these cases are PREAJ. Examples: “[was profound anyway]” (ahlct001); “[being bleak so] here is…” (ahlct001); “this [was easy enough] for…” (ahlct006); “you [‘re unlikely just] to casually…” (ahlct015). The algorithm used in this study improves both the precision and recall of PREAJ: when used in a statement, LINKING_V (+ NOT or ADV) (+ NOT or ADV) + ADJ + anything but ADJ or NOUN or one or ones; when used in questions: BE (+ NOT) (+ NOT or ADV) + SUBPRP (+ NOT or ADV) + ADJ + anything but ADJ or NOUN; other situations: anything but the or QUANPRP + ADJ + IN or WRB or WP or WP$ or WDT. 

Adverb sub-categories
79.	Place adverb (PLAAD). Aboard, above, abroad, across, ahead, alongside, around, ashore, astern, away, behind, below, beneath, beside, downhill, downstairs, downstream, east, far, hereabouts, indoors, inland, inshore, inside, locally, near, nearby, north, nowhere, outdoors, outside, overboard, overland, overseas, south, underfoot, underground, underneath, uphill, upstairs, upstream and west. This study follows Nini’s (2014) algorithm, which require these words not POS tagged as NNP. 
80.	Time Adverb (TMAD). Afterwards, again, earlier, early, eventually, formerly, immediately, initially, instantly, late, lately, later, momentarily, now, nowadays, once, originally, presently, today, tomorrow, tonight and yesterday. 
81.	Nonfactive adverb (NFAD). Such as: accordingly, confidentially, figuratively and frankly etc. See Biber (2006: 32).
82.	Attitudinal adverb (ATAD). Such as: amazingly, astonishingly, conveniently, and disturbingly etc. See Biber (2006: 32).
83.	Factive adverb (FAD). Such as: actually, always, certainly, definitely, indeed and inevitably etc. See Biber (2006: 32).
84.	Likelihood adverb (LKAD). Such as: apparently, evidentially, perhaps, possibly, predictably, probably and roughly etc. See Biber (2006: 32).
Conjunction subcategories
85.	Causative adverbial subordinator (CAUSA). Because. Nonstandard spellings, such as ‘cause and cuz, are already standardized into because so because suffices here.
86.	Conditional adverbial subordinator (CONDA). If and unless.
87.	CONTRASTIVE adverbial subordinator (CONTA). Although, tho, though, even if, but, however, no matter how, whereas, despite, nevertheless, in spite of, regardless of, as opposed to, in contrast, instead of and notwithstanding. 
88.	Other adverbial subordinator (OTHA). Since, while, whilst, whereupon, whereas, whereby, such/so that + anything but NOUN or ADJ, inasmuch as, forasmuch as, insofar as, insomuch as, as long as and as soon as. 
Modal subcategories
89.	Possibility modal (POSMD). Can, may, might, could and their contracted forms.
90.	Necessity modal (NECMD). Ought, should and must. 
91.	Predictive modal (PRMD). Will, would, shall, and their contracted forms.
Stance-related expression
92.	Conjunct (CNJT). Alternatively, consequently, conversely, eg, e.g., furthermore, hence, however, i.e., instead, likewise, moreover, namely, nevertheless, nonetheless, notwithstanding, otherwise, similarly, therefore, thus, viz, in comparison / contrast / particular/addition/conclusion/consequence/sun/summary/any event/any case/other words, for example/instance, by contrast/comparison, as a result/consequence, on the contrary and on the other hand. Three words are deleted as they require punctuations to be identified, namely, else, rather, altogether. 
93.	Downtoner (DTN). Almost, barely, hardly, merely, mildly, nearly, only, partially, partly, practically, scarcely, slightly and somewhat.
94.	Amplifier (AMP). Absolutely, altogether, completely, enormously, extremely, fully, greatly, highly, intensely, perfectly, strongly, thoroughly, totally, utterly and very. In the non-test version, so, terribly, awfully and vastly are added based on Appendix A.
95.	Hedge (HEDG). At about, something like, more or less, almost, maybe, X sort/kind of, where X is anything but NMOD and WHO, making sure that kind and sort are not true nouns. In the non-test version, a (little) bit is also added based on Appendix A. 
96.	Emphatic (EMP). Just, really, most, more, real/so + ADJ, such a, a lot, for sure, DO + VB.  As mentioned above, in Biber (1988) and Nini (2014), DO also includes doing and done, which is problematic. See DO. In the non-test version, anyway, especially, full, even, much, totally and always are also added based on Appendix A.
97.	Polite expression (PLEP). Thank, thanks, please and excuse me.
98.	General evidential expression (EVIEP) Such as: amazing, bad, beautiful, best and crazy etc. See (Precht, 2008: 108). 
